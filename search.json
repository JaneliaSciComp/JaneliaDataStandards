[
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "How to contribute",
    "section": "",
    "text": "How to contribute\nThanks for considering contributing to Janelia’s data standards!\nIn order to keep things simple, please refrain from forking this repository. Instead, create a new branch with your changes in this repository and create a pull request against the main branch (or any other suitable branch). Alternatively, if your changes are small and reasonable, you may commit them to the main branch yourself. If you don’t have edit rights in this repository but would like them, please contact Virginia Scarlett.\nPosts in a format suitable for quarto, such as quarto markdown (.qmd) or a notebook (.ipynb) can be added to /posts/. Use the existing posts as a template, at least for the header block. Quarto will render these files to html, i.e., build the static site files.\nThe workflow for submitting a PR (should you wish to do so) is as follows:\nClone the repo &gt; create your feature branch &gt; do some work &gt; Optionally do quarto preview to host the site locally and see it in your browser &gt; git commit and git push as usual.\nTo preview the site or build it locally, you will need quarto installed on your computer. Neither of these is strictly necessary, since a GitHub action should render the site files remotely for you. Changes may take up to 20 minutes to be reflected on the website.\nThe rendered site pages are automatically stored in, and deployed from, the gh-pages branch, so please do not modify that branch."
  },
  {
    "objectID": "posts/file_formats_introduction.html",
    "href": "posts/file_formats_introduction.html",
    "title": "Introduction to Microscopy File Formats",
    "section": "",
    "text": "Introduction\n\nEase of use\nScalability\nFAIRness\n\nUltra base formats\n\nBinary/Hard to classify\nText\n\nBase formats\n\nXML and JSON\nTIFF\nHDF5\nZarr\nN5\nTileDB\n\nGeneral-purpose formats\n\nOME-TIFF\nOME-NGFF\nProprietary\nBIDS\n\nSpecialty file formats\n\nBigDataViewer\nH5J"
  },
  {
    "objectID": "posts/file_formats_introduction.html#outline",
    "href": "posts/file_formats_introduction.html#outline",
    "title": "Introduction to Microscopy File Formats",
    "section": "",
    "text": "Introduction\n\nEase of use\nScalability\nFAIRness\n\nUltra base formats\n\nBinary/Hard to classify\nText\n\nBase formats\n\nXML and JSON\nTIFF\nHDF5\nZarr\nN5\nTileDB\n\nGeneral-purpose formats\n\nOME-TIFF\nOME-NGFF\nProprietary\nBIDS\n\nSpecialty file formats\n\nBigDataViewer\nH5J"
  },
  {
    "objectID": "posts/file_formats_introduction.html#ultra-base-file-formats",
    "href": "posts/file_formats_introduction.html#ultra-base-file-formats",
    "title": "Introduction to Microscopy File Formats",
    "section": "Ultra base file formats",
    "text": "Ultra base file formats\n\nBinary/Hard to classify\nWe use the term “binary format” as a generic term to refer to file formats that can be easily read by computers. If files defy classification into more standardized categories, they may be only referred to as “binary”. Most of the file formats described in other sections are, at least in part, binary in the sense that they have text-encoded and non-text components (e.g. metadata files and chunk files, respectively). By ‘binary formats’, we mean prescribed arrangements of bytes in a single file designed for specific applications.\nTwo examples of binary formats we use at Janelia are Enhanced FIBSEM DAT (Chris Barnes’ DAT toolkit, Janelia’s DAT toolkit) and Keller Lab Block (KLB) (bitbucket repository). These formats are not derived from any broader standard and can only be interpreted by dedicated software specifically written for them.\nBinary formats can be useful at acquisition, especially in live cell imaging or in fluorescence imaging, where speed is paramount. They may also provide storage solutions, for example, by allowing for the use of completely novel compression schemes.\nIn our experience, these formats are usually not very FAIR. Often, they are only maintained by a handful of people who designed the format for a special use case. The Keller Lab has made significant efforts to enhance the interoperability of KLB by providing converters for platforms like ImageJ, MATLAB, and some proprietary libraries. While these efforts improve accessibility, we still recommend against publishing data in these specialized formats.\nA more widely adopted binary format is MRC (CCP-EM, Cheng et al. 2015), designed for electron cryo-microscopy and tomography. The accompanying python library is being actively maintained. However, the format and tooling are still maintained by a relatively small community. Multi-language support is lacking, and MRC does not offer the flexibility of formats that separate the storage backend from the user API (like Zarr or HDF5). This limited flexibility is a barrier to widespread adoption. We encourage users of the MRC format to consider using Zarr or HDF5-based formats instead, to promote convergence on a small number of technologies with robust development communities.\n\n\nText\nWhile all files on a computer are ultimately binary, text-based files are binary files that can be decoded into human-readable text using character encodings. ASCII and Unicode are widely used standards for mapping bytes to letters and symbols. Unicode, which includes ASCII as a subset, supports a large range of characters across many languages. These encodings enable human-readable text to be represented as a binary sequence (0s and 1s) that computers can store and transmit. Text formats generally use encodings such as UTF-8, UTF-16, or ASCII to store textual data.\nIn microscopy, the two main text formats are XML and JSON, discussed below. Another example worth mentioning is RDF (Resource Description Framework), which, although not strictly a text format, is often represented as text. RDF enables more descriptive relationships beyond simple key-value pairs, making it a powerful tool for modeling semantic data.\nFor small amounts of data, storing the data as structured text is convenient. However, for large amounts of data, say, megabytes, text formats become unwieldy. This is why, in microscopy, text formats are usually reserved for metadata, while the image data themselves are stored in more space-efficient formats."
  },
  {
    "objectID": "posts/file_formats_introduction.html#base-file-formats",
    "href": "posts/file_formats_introduction.html#base-file-formats",
    "title": "Introduction to Microscopy File Formats",
    "section": "Base file formats",
    "text": "Base file formats\nNext, we summarize some “base” formats that are commonly used in bioimaging and that we find noteworthy. These formats serve as generic storage technologies that have often been further refined to suit a particular application. This list covers a wide variety of use cases, but it is not exhaustive - some applications might benefit from a format not listed here.\n\nXML and JSON\nXML (eXtensible Markup Language) and JSON (JavaScript Object Notation) are standardized text formats designed for exchanging data between programs. Both are human-readable and readable by software programs with the appropriate libraries. XML is older, more verbose, and the tools for structuring and parsing it are more mature. JSON is newer, more readable, and the schema language JSONSchema is only moderately mature. XML is a bit more expressive, allowing for more complex hierarchies and dedicated namespaces. JSON is more lightweight and straightforward to parse.\nThe simplest way to store metadata (attributes of the data such as resolution, axis order, units, etc.) is in the form of plain text, as in the methods section of a paper. However, plain text has two drawbacks: (1) it separates the data and the metadata into separate files, and (2) it is not directly interpretable by image-viewing tools. XML and JSON solve these problems by embedding machine-readable metadata directly within the data files or folders. XML or JSON metadata usually follow a schema, which defines the structure and organization of the metadata. With a schema, such as the OME schemas, software tools can reliably locate specific metadata fields. For example, if the viewer tool knows where to extract the pixel spacing information, it can then display the position of your cursor in real-world units, e.g. nanometers.\nXML and JSON are both useful formats for storing microscopy metadata. While the original OME-XML standard recommended storing the actual image data in XML, this practice was abandoned decades ago because it’s very unwieldy. Nowadays, most image formats have the data in a binary component and the metadata in an XML or JSON component.\nAs JSON is newer, more lightweight, and human-readable, newer formats tend to store their metadata in JSON. However, microscopy formats that store their metadata in XML are still widespread.\n\n\nTIFF\nTIFF is a well-established, non-chunked image format that has been widely trusted since its first release in 1986. It is supported by most image analysis tools and remains a staple in scientific and industrial imaging. TIFFs can be compressed with or without loss of data (lossy or lossless), though compression is lossless by default. JPEG compression is often more straightforward for TIFF than for chunked formats.\nA single TIFF file can store multiple 2D images. In these multi-page TIFFs, metadata embedded in the file indicate to the viewer software where each image starts and ends. Multi-page TIFFs are particularly useful for storing sets of related images, such as multiscale pyramids, z-stacks, or image-thumbnails pairs. If your top priorities are ease and FAIRness, TIFF may be a good choice, because it’s so widespread and well-supported.\nThe scalability of TIFF is limited, however. Once a TIFF file is more than a few GB, image viewers are likely to struggle with it, because they are limited by the size of the computer’s memory. For large datasets or multi-dimensional images, chunked formats may be more suitable.\n\n\nHDF5\nHDF5 is a chunked file format for storing n-dimensional arrays, dating back to 1998. Like TIFF, it can be read by many tools, and many varieties exist. It is possible to store extremely complex datasets in a single HDF5 file, including heterogeneous arrays where each element is itself a complex object. You can think of HDF5 as an entire file system contained within a single file. The main differences between HDF5 and a folder on your file system are that (1) the individual HDF5 chunks can be accessed with a lot less overhead than individual files, and (2) data are not accessed through your operating system but rather through the GUI HDFView or the HDF5 API, which has been implemented in all the major programming languages. Smart use of data buffers and caches make HDF5 quite good at loading giant data into memory efficiently.\nThe crucial drawback of HDF5 is that it is slow to access in the cloud, specifically object storage (such as Amazon S3, Google GCS, or Microsoft ADL). In an unoptimized HDF5 file, it can be time consuming to locate the chunks inside an HDF5 container, particularly over the internet. One way to cloud-optimize an HDF5 file is to put the chunk location information into a single header so that it all can be read in one operation. (For more tips on cloud-optimized HDF5, see this forum discussion and this talk.) Additionally, there are intermediate services you can use (notably HSDS, also see this article). However, any of these options is an extra layer of effort for you and/or your users if you want to share HDF5 files over the cloud.\nWe consider HDF5 reasonably FAIR. It is maintained by a non-profit organization, the HDF Group. Despite this top-down governance structure, the HDF Group is receptive to feedback from the microscopy community. Many scientific image viewers are equipped to read and write HDF5, making it a sensible choice for data that are meant to be downloaded locally or interacted with on an HPC cluster.\n\n\nZarr\nZarr is a relatively new project created by Alistair Miles in 2015, and shares many similarities with HDF5. Both projects offer APIs in a variety of languages for reading, writing, and compressing chunks of huge n-dimensional arrays. Both use a hierarchical data model consisting of groups of chunked arrays. Both are based on a layered computation model: the storage, storage access/transformers, filters/codecs, and application layers are conceptually separated, allowing the developer to mix and match them. Both come in many variants tailored to specific scientific domains.\nA key difference is that while an HDF5 dataset is a single file that must be read with an HDF5 library, an analogous Zarr dataset would be a folder containing many small files that can theoretically be read by anything that can read files. This creates a different kind of overhead than HDF5. Zarr is more cloud-friendly than HDF5, but it can be less friendly on a local computer or HPC cluster. For example, it can be very slow to move a Zarr dataset from one location to another on your computer. Zarr attempts to mitigate this issue using a technique called sharding, which was recently introduced with the latest version of Zarr (v.3). Sharding is another layer of data organization in addition to chunking, where chunks reside within shards. The shards will be folders, if the storage backend is a file system. Nesting chunks within shards can substantially reduce the number of files, improving local performance, but it does make implementation more complex.\nBecause Zarr is such a new project, there are some limits to its ease of use. If you are using it for a highly novel, specialized scientific application, you may encounter issues with missing features or incomplete standardization. For example, the existing compression schemes may be inadequate, or it may not support complex transformations. Still, there are perhaps a dozen scientific image viewers that support OME-Zarr, which bodes well for its future.\n\n\nN5\nN5 is a format created by Stephan Saalfeld in 2017. The main motivation behind it was to simplify the parallel writing of chunks relative to HDF5. As noted earlier, this was also a motivating factor in the creation of Zarr. Since N5 was created independently of Zarr at around the same time and with similar motivations, the two formats are functionally quite similar. Like Zarr, it stores chunks in separate files on a file system (or keys in a cloud store) and metadata as JSON files. Furthermore, it comes with an API that can read and write from the HDF5 and Zarr formats in addition to the N5 format, thereby unifying access to chunked data formats.\nBecause of their close similarity, N5 and Zarr generally interoperate well: many libraries that can read and write Zarr can read and write N5 (and vice versa). As Zarr has become more prevalent, with a wider community, we generally recommend using it to N5, unless your application would benefit from an N5-specific feature:\n\nN5 allows “partial” chunks where all Zarr chunks must be the same size. The difference appears near the upper boundary of the array if the array size is not evenly divisible by the chunk size. N5 chunks will end where the array does, but Zarr chunks need to be filled with “empty” data.\nN5 can read and write the special-case label multi-set data type used by Paintera. Zarr does not currently support label multi-sets.\n\nAlso like Zarr, the ease-of-use of N5 largely will vary across software ecosystems. At this time, Fiji and neuroglancer have good support for N5. In particular, the N5 plugins for Fiji enable users to read and write to a variety of formats, including OME-Zarr, without needing to write code. For that reason, the N5-API may be a friendly entry-point to chunked formats for many researchers.\n\n\nTileDB\nTileDB is a modern file format and database management system optimized for highly parallel reads and writes of n-dimensional arrays. It offers excellent performance on sparse arrays, although this use case is not common in bioimaging. Like Zarr, it’s very cloud-friendly. Similar to Zarr and HDF5, it separates the storage, compression, and compute layers, providing flexibility in storage options (e.g., file systems or object storage) and access methods (e.g., Spark, Dask, or MariaDB). TileDB also supports basic versioning: its chunks are immutable, enabling users to preserve and inspect previous versions of data.\nOne standout feature of TileDB is that it will be familiar to data engineers accustomed to tabular data. When data are stored following recommended conventions, users can query “tiles” (chunks) of n-dimensional arrays using SQL. It also has a very robust development community and strong multi-language support.\nTileDB is gaining traction in scientific fields like geospatial analysis and genomics, but adoption in microscopy has been slower. While the paid tier TileDB Cloud offers an image viewer, among other features, and there is a Napari plugin for TileDB, the format can feel overly complex for many microscopy developers’ needs. If you’re just sharing some data on S3 or in a repository, we recommend Zarr as a more FAIR choice. The OME-Zarr format in particular is designed with microscopy in mind. However, TileDB may excel in enterprise-scale scenarios, such as building repositories or handling large, diverse datasets with complex access requirements. In such cases, its scalability and versatility could make it a stronger choice than Zarr."
  },
  {
    "objectID": "posts/file_formats_introduction.html#general-purpose-file-formats",
    "href": "posts/file_formats_introduction.html#general-purpose-file-formats",
    "title": "Introduction to Microscopy File Formats",
    "section": "General-purpose file formats",
    "text": "General-purpose file formats\nBelow we describe a selection of versatile file formats that are appropriate for publication or everyday use. Building on the base formats described above, they are specifically designed to accommodate microscopy data. With the exception of BIDS, all are widely used at Janelia.\n\nOME-TIFF\nOME-TIFF is a specification of the widely used TIFF format that is tailored for microscopy images. It integrates metadata based on the OME-XML specification, embedding an OME-XML header block directly into the TIFF file. Developed in the early 2000s, OME-TIFF provides a robust framework for storing both image data and richly detailed metadata (Goldberg et al. 2005). OME-TIFF was originally designed for fluorescence imaging, and was adapted in 2019 to accommodate whole slide imaging (Besson et al. 2019). However, new development of the OME-TIFF specification is limited, as the community shifts to OME-NGFF and considers newer metadata frameworks (Hammer et al. 2021) that may be based on RDF and JSON-LD.\nThe OME data model supports a wide range of metadata, including image characteristics (e.g., resolution, number of focal planes, time points, and channels), as well as details about the acquisition instrument, experimenters, experimental design, and more. Any software that can read TIFF files can also open OME-TIFFs. Additionally, most scientific image viewers are equipped to interpret at least the core metadata of OME-TIFF, making this format broadly interoperable. Since OME-TIFFs are TIFFs, they can store multiple image planes, but they also lack chunking capabilities.\nIf you choose to save your data as a TIFF, it’s best practice to use the OME-TIFF specification. OME-TIFF can accommodate more of your metadata than a standard TIFF, which lacks microscopy-specific fields. Even if you don’t currently need all the metadata contained in the OME-XML, users analyzing or processing your data in the future may benefit from having access to this additional information. In contrast, custom metadata schemas or plain text notes won’t be supported by existing tools.\n\n\nOME-NGFF\nLike OME-TIFF, OME-NGFF is a specification of a more generic file format that is tailored for microscopy. OME-NGFF is, for the time being, synonymous with OME-Zarr; “NGFF” stands for “Next Generation File Format”. An OME-NGFF data set consists of a Zarr hierarchy, which includes certain metadata files in standard locations in JSON format. OME-NGFF is much newer than OME-TIFF; its first release was in 2021 (Moore et al. 2023). It supports some types of ancillary data, namely high-content screening (HCS) data and label images (e.g. from image segmentation).\nOME-NGFF is much more scalable than OME-TIFF, being a chunked format. It is also designed to handle multi-dimensional data, though it specifies a limit of 5D. Being Zarr-based, OME-NGFF is optimized for the cloud, so it’s a great format for data publication. It will soon have strong support for complex coordinate transformations, a feature that is lacking in all the other microscopy formats, to our knowledge.\nA weakness of OME-NGFF is that the schema is changing rapidly (though perhaps this is also a strength). Tools for working with it are immature, making it that much more complicated to learn. The metadata schema is also missing much material that is present in OME-XML, for example, instrument settings and experiment details.\nEven though OME-NGFF is still an emerging standard, we encourage the community to use and contribute to this format. OME is a long-standing leader in microscopy analysis standards and tools, and we are optimistic that the community will come together around this new format.\n\n\nProprietary\nProprietary file formats are developed by a microscopy manufacturer, and are designed to be viewed with the manufacturer’s software. Examples include .nd2 for Nikon, .lif for Leica, .oib or .oif for Olympus, .lsm or .czi for Zeiss, or .ims for Imaris. Some of these formats are variants of the base formats described above; for example, Imaris files are HDF5-based. They usually perform well in their corresponding proprietary viewers, but cannot readily be opened by open-source viewers. Luckily, the Bio-formats project has made it possible to open these formats in several open-source viewers, though sometimes metadata can be lost in translation. Viewers that use the Bio-formats library often provide functionality to either translate on the fly or convert the file to a new format. There are also free versions of some proprietary viewers, such as Zeiss Zen Lite and Leica LAS AF Lite.\nThe FAIRness of these formats is a tricky question. On the one hand, converting to an open-source format such as OME-TIFF or OME-NGFF is appealing because it makes the data accessible to users who are used to, or limited to, free, open-source viewers. On the other hand, some metadata may be lost during conversion. Additionally, conversion duplicates your data size and storage costs. When considering publishing data in a proprietary format, there is no one-size fits all solution. You should consider your audience and your budget. You may try conversion, and then assess whether any metadata have been lost by comparing what you see in the vendor interface against what you see in, say, ImageJ after conversion. The vendor may also offer tools to export the metadata in a text format, say plain text or XML. In that case, you could convert the image to an open-source format, which should retain at least the pixel/voxel data in full, and then you could archive and/or publish the much smaller text export of the metadata.\n\n\nBIDS\nThe Brain Imaging Data Structure (BIDS) is a widely used specification for organizing medical image data. It is not itself a storage backend; rather, it defines a consistent and structured way to arrange files and folders and to format JSON metadata. Originally developed by the MRI community, BIDS quickly gained traction in that field and has since been extended to support other imaging modalities, including EEG, iEEG, PET, and qMRI. Efforts to add microscopy to that list are relatively recent, having started in earnest in 2021 (see this forum discussion), and led to the publication of the microscopy extension in 2022 (Bourget et al. 2022).\nThe BIDS microscopy specification adds additional standards on top of OME-NGFF and OME-TIFF. The BIDS metadata complement, rather than replace, the metadata embedded in OME-TIFF headers or OME-NGFF JSON files. As a result, researchers are required to maintain metadata in two locations, which can introduce redundancy and potential inconsistencies. The authors worked to mitigate these drawbacks by specifying only the minimal metadata needed for image analysis.\nAdopting BIDS can help your data to integrate seamlessly with BIDS-compatible tools or repositories, such as the DANDI Archive, which encourages the use of BIDS for many data types. Even if you do not require BIDS-specific tooling, modeling your Zarr or HDF5 data hierarchies according to BIDS principles can be a sensible approach to organization. However, it is worth noting that the BIDS microscopy standard is still maturing. Learning it takes time, and managing redundant metadata carries risks. For these reasons, we do not currently use BIDS for our microscopy data, though it is a robust and valuable standard, particularly for medical imaging applications."
  },
  {
    "objectID": "posts/file_formats_introduction.html#specialty-file-formats",
    "href": "posts/file_formats_introduction.html#specialty-file-formats",
    "title": "Introduction to Microscopy File Formats",
    "section": "Specialty file formats",
    "text": "Specialty file formats\nThese are formats you’re more likely to inherit than select, unless you have a particular reason to. They were created to solve particular problems the other formats couldn’t solve.\n\nBigDataViewer\nThe BigDataViewer format is based on HDF5 or N5 for data and XML for metadata, and is designed for 3D multi-view light sheet microscopy data. As the name suggests, it allows for seamless viewing of terabyte-scale images. It uses both the pyramid and chunking techniques – each dataset is stored as a series of downsampled volumes, and each volume is stored as a chunked array. This allows the lower resolution slices to be rendered almost instantly, and the higher resolution slices to be loaded soon after, if the user continues browsing in the same region.\nThe BigDataViewer software, which comes with Fiji, can view any file format that is in the Bio-formats library using the LOCI Bioformats plugin, and also natively supports the Imaris (.ims) file format. However, most of those formats don’t readily support large, multiview image datasets such as those from Selective Plane Illumination Microscopy (SPIM) systems. For SPIM or light sheet fluorescence microscopy (LSFM) data, the BigDataViewer format may be a good choice. It integrates well with Fiji’s Multiview Reconstruction plugins, as well as Fiji’s BigStitcher plugin, and is more standardized than inventing your own custom HDF5 structure and metadata schema.\n\n\nH5J\nH5J is a “visually lossless” file format developed at Janelia Research Campus for storing multichannel 3D image stacks. An H5J file is simply a standard HDF5 file with a specific hierarchy structure. It uses the H.265 codec (a.k.a. HEVC or High Efficiency Video Coding) and different compression ratios per channel to obtain better compression than is readily achievable with OME-Zarr. H5J files can be read by VVD Viewer, the Janelia Workstation, web-vol-viewer, and web-h5j-loader. They can be read and written using Fiji or Vaa3D. You can print the metadata using any HDF5-compliant library, and/or export them to JSON.\nH5J is arguably more space efficient than OME-Zarr, but its lower adoption is a significant drawback. H5J is not nearly as widespread as OME-Zarr, and its development community is limited. If you’re tied to HDF5, H5J is a reasonably accessible resource for achieving high compression without reinventing the wheel. However, even at Janelia, significant effort is being made to improve the performance of OME-Zarr, to support the community effort to shift to a small number of well-supported formats."
  },
  {
    "objectID": "definitions.html",
    "href": "definitions.html",
    "title": "Definitions",
    "section": "",
    "text": "Please note that this is a living document. Definitions are preliminary and subject to change.\n\nBasic definitions\n\narray\nimage\npixel\nsample\nvoxel\n\nOther definitions\n\naxis\nbit-depth\ndomain\ndownsampling\nfield of view\nfiltering\ngroup\nhierarchy\ninterpolation\norigin\nphysical\nquantization\nresampling\nresolution\n\n\n\n\n\n\nAn n-dimensional collection of discrete samples whose domain is a regular discrete (integer) grid.\nRelated terms: sample, image, hierarchy\n\n\n\nA static set of coherent visual information. For our purposes, ‘image’ and ‘digital image’ may be used interchangeably.\nImages can be represented in compact forms, for example as a compressed sequence of bytes or as a discrete function over a finite domain. For our purposes, the word ‘image’ by itself refers to raster images produced by displaying arrays and array-like data structures on a screen. Unless otherwise specified, this rastering occurs at regular equispaced intervals, the pixel pitch.\nAn image is an abstract notion distinct from its representation, e.g. a discrete digital array. Colloquially, ‘array’ and ‘image’ are often used interchangeably. However, a rigorous technical definition separates the two, so that an image (a static set of coherent visual information) may be constituted by several arrays, for example.\nRelated terms: array, sample, pixel, voxel, axis, dimension\n\n\n\nA single sample of a two-dimensional image.\nRelated terms: sample, voxel\n\n\n\nA digital number representing a measurement of the energy sensed by a particular cell on a sensor at a discrete point in time. Because cells on a sensor correspond to elements of an array and pixels of an image, sample is often used interchangeably with pixel.\nRelated terms: pixel, voxel, image, array\n\n\n\nA single sample of a three-dimensional image.\nRelated terms: sample, pixel\n\n\n\n\n\n\nThe physical interpretation of a discrete, numeric, finite dimension. Generally represented with a 1D variable that is strictly monotonic and has the same name as the axis it represents. An axis must have physical units.\n\n\n\nThe number of bits used in the quantization of a digital image that defines the number of unique values that can be represented by samples. For example, samples of images with a bit depth of (“8-bit images”) can take up to 256 unique values.\nRelated terms: quantization\n\n\n\nAn independent extent of a domain. A domain has \\(N\\) dimensions where \\(N\\) is the minimum number of coordinates needed to identify any particular point within the domain. The length of a discrete, numeric, finite dimension establishes the number of indexable locations along that dimension.\n\n\n\nA set of discrete locations in abstract space. A domain, or any location within a domain, may be described by multiple variables, but any given variable has only one domain. A domain has zero or more dimensions. The component dimensions of a domain need not be numeric, but when they are, the domain may be thought of as situated in a coordinate space. If a domain’s dimensions are all axes, then that domain is situated in a physical space.\n\n\n\nThe act of resampling an image to a lower sample density (higher pixel spacing), often by an integer factor. Sometimes this can require interpolation.\nRelated terms: resampling, resolution, interpolation\n\n\n\nThe physical extent of the observed space. In microscopy, FOV may be expressed as the diameter of the circular view seen through the eyepiece. In scientific bioimaging, FOV is typically expressed as the horizontal, vertical, and/or diagonal extent of the space captured by the digital sensor. For example, the FOV for a 2D image may be \\(44mm\\) by \\(22mm\\), where \\(44mm\\) is the width and \\(22mm\\) is the height of the observed space.\n\n\n\n\nUsually referes to a convolution operation (a local, linear operation on the intensity values of an image).\nAny operation that modifies the intensity values of an image.\n\n\n\n\nSee hierarchy.\n\n\n\nA collection of nodes, connected in a tree-like structure. A node can be either: 1. A group, i.e., a node that can have child nodes, and can contain metadata, but cannot contain array data. 2. An array. Array nodes cannot have child nodes.\nRelated terms: group, array\n\n\n\nA process that, given an image, produces new samples at points in the domain not on the discrete image grid.\nThe most common methods for interpolation are ‘nearest-neighbor’, ‘bi-/tri-/n-linear’, ‘cubic’, and ‘windowed sinc’.\nRelated terms: resampling, downsampling\n\n\n\nA special location that acts as a reference point, relative to which relative to which other locations are defined. Unless otherwise specified, the image’s origin is the same as the array’s origin (assuming the image is produced from an array). An array’s origin is typically the point in the discrete domain with the minimum index (usually zero) for all dimensions. Physical or anatomical spaces can also have origins; for example, in MR imaging, the anterior/posterior commissure is commonly regarded as an origin for the brain.\nThe term ‘offset’ is sometimes used to refer to the origin.\n\n\n\nRelating to quantities or measurements of the real world.\nExamples:\n\nsample intensities measured by a physical sensor\n\nphoton count\nHounsfield unit\n\ndistances / areas / volumes / times measured in images in physical units (\\(\\mu m\\), \\(mm\\), seconds)\n\n“the area of segment \\(A\\) is \\(12 mm^2\\)”\n“mitosis begins at time = \\(3.2 s\\)”\n\n\nNon-examples:\n\nsample intensities not derived from sensors\n\nsegmentation id\nthe output of a deep neural network model\n\ndistances / areas / volumes / times described by sample / array indexes\n\n“the area of segment \\(B\\) is \\(85\\) pixels”\n“mitosis begins at frame \\(51\\)”\n\n\n\n\n\nA process that converts a physical or continuous value to a digital representation with a particular precision. Samples of a quantized image can take one of a finite set of values defined by its bit depth.\nRelated terms: bit-depth\n\n\n\nA process that generates a new array representing an image at a new resolution.\nThe new resolution is often an integer multiple or fraction of the original image resolution, but need not be. Resampling methods often consist of filtering and interpolation steps.\nRelated terms: downsampling, interpolation, resolution\n\n\n\nThe smallest difference in signal quantity that can be discriminated by a device or system. In the case of analog to digital signal conversion, resolution is determined by the number of bits used to represent the signal.\nColloquial uses of the term ‘resolution’ include the total number of samples in each dimension of an image (e.g., 640 by 420), and the set of spatial sampling intervals for an image (e.g. ‘spacing’, ‘pixel spacing’, or ‘pixel resolution’). For clarity, it may be prudent to avoid using the term ‘resolution’ to describe either the number of samples in an image or the spacing between samples.\nRelated terms: bit-depth, resampling"
  },
  {
    "objectID": "definitions.html#basic-definitions",
    "href": "definitions.html#basic-definitions",
    "title": "Definitions",
    "section": "",
    "text": "An n-dimensional collection of discrete samples whose domain is a regular discrete (integer) grid.\nRelated terms: sample, image, hierarchy\n\n\n\nA static set of coherent visual information. For our purposes, ‘image’ and ‘digital image’ may be used interchangeably.\nImages can be represented in compact forms, for example as a compressed sequence of bytes or as a discrete function over a finite domain. For our purposes, the word ‘image’ by itself refers to raster images produced by displaying arrays and array-like data structures on a screen. Unless otherwise specified, this rastering occurs at regular equispaced intervals, the pixel pitch.\nAn image is an abstract notion distinct from its representation, e.g. a discrete digital array. Colloquially, ‘array’ and ‘image’ are often used interchangeably. However, a rigorous technical definition separates the two, so that an image (a static set of coherent visual information) may be constituted by several arrays, for example.\nRelated terms: array, sample, pixel, voxel, axis, dimension\n\n\n\nA single sample of a two-dimensional image.\nRelated terms: sample, voxel\n\n\n\nA digital number representing a measurement of the energy sensed by a particular cell on a sensor at a discrete point in time. Because cells on a sensor correspond to elements of an array and pixels of an image, sample is often used interchangeably with pixel.\nRelated terms: pixel, voxel, image, array\n\n\n\nA single sample of a three-dimensional image.\nRelated terms: sample, pixel"
  },
  {
    "objectID": "definitions.html#other-definitions",
    "href": "definitions.html#other-definitions",
    "title": "Definitions",
    "section": "",
    "text": "The physical interpretation of a discrete, numeric, finite dimension. Generally represented with a 1D variable that is strictly monotonic and has the same name as the axis it represents. An axis must have physical units.\n\n\n\nThe number of bits used in the quantization of a digital image that defines the number of unique values that can be represented by samples. For example, samples of images with a bit depth of (“8-bit images”) can take up to 256 unique values.\nRelated terms: quantization\n\n\n\nAn independent extent of a domain. A domain has \\(N\\) dimensions where \\(N\\) is the minimum number of coordinates needed to identify any particular point within the domain. The length of a discrete, numeric, finite dimension establishes the number of indexable locations along that dimension.\n\n\n\nA set of discrete locations in abstract space. A domain, or any location within a domain, may be described by multiple variables, but any given variable has only one domain. A domain has zero or more dimensions. The component dimensions of a domain need not be numeric, but when they are, the domain may be thought of as situated in a coordinate space. If a domain’s dimensions are all axes, then that domain is situated in a physical space.\n\n\n\nThe act of resampling an image to a lower sample density (higher pixel spacing), often by an integer factor. Sometimes this can require interpolation.\nRelated terms: resampling, resolution, interpolation\n\n\n\nThe physical extent of the observed space. In microscopy, FOV may be expressed as the diameter of the circular view seen through the eyepiece. In scientific bioimaging, FOV is typically expressed as the horizontal, vertical, and/or diagonal extent of the space captured by the digital sensor. For example, the FOV for a 2D image may be \\(44mm\\) by \\(22mm\\), where \\(44mm\\) is the width and \\(22mm\\) is the height of the observed space.\n\n\n\n\nUsually referes to a convolution operation (a local, linear operation on the intensity values of an image).\nAny operation that modifies the intensity values of an image.\n\n\n\n\nSee hierarchy.\n\n\n\nA collection of nodes, connected in a tree-like structure. A node can be either: 1. A group, i.e., a node that can have child nodes, and can contain metadata, but cannot contain array data. 2. An array. Array nodes cannot have child nodes.\nRelated terms: group, array\n\n\n\nA process that, given an image, produces new samples at points in the domain not on the discrete image grid.\nThe most common methods for interpolation are ‘nearest-neighbor’, ‘bi-/tri-/n-linear’, ‘cubic’, and ‘windowed sinc’.\nRelated terms: resampling, downsampling\n\n\n\nA special location that acts as a reference point, relative to which relative to which other locations are defined. Unless otherwise specified, the image’s origin is the same as the array’s origin (assuming the image is produced from an array). An array’s origin is typically the point in the discrete domain with the minimum index (usually zero) for all dimensions. Physical or anatomical spaces can also have origins; for example, in MR imaging, the anterior/posterior commissure is commonly regarded as an origin for the brain.\nThe term ‘offset’ is sometimes used to refer to the origin.\n\n\n\nRelating to quantities or measurements of the real world.\nExamples:\n\nsample intensities measured by a physical sensor\n\nphoton count\nHounsfield unit\n\ndistances / areas / volumes / times measured in images in physical units (\\(\\mu m\\), \\(mm\\), seconds)\n\n“the area of segment \\(A\\) is \\(12 mm^2\\)”\n“mitosis begins at time = \\(3.2 s\\)”\n\n\nNon-examples:\n\nsample intensities not derived from sensors\n\nsegmentation id\nthe output of a deep neural network model\n\ndistances / areas / volumes / times described by sample / array indexes\n\n“the area of segment \\(B\\) is \\(85\\) pixels”\n“mitosis begins at frame \\(51\\)”\n\n\n\n\n\nA process that converts a physical or continuous value to a digital representation with a particular precision. Samples of a quantized image can take one of a finite set of values defined by its bit depth.\nRelated terms: bit-depth\n\n\n\nA process that generates a new array representing an image at a new resolution.\nThe new resolution is often an integer multiple or fraction of the original image resolution, but need not be. Resampling methods often consist of filtering and interpolation steps.\nRelated terms: downsampling, interpolation, resolution\n\n\n\nThe smallest difference in signal quantity that can be discriminated by a device or system. In the case of analog to digital signal conversion, resolution is determined by the number of bits used to represent the signal.\nColloquial uses of the term ‘resolution’ include the total number of samples in each dimension of an image (e.g., 640 by 420), and the set of spatial sampling intervals for an image (e.g. ‘spacing’, ‘pixel spacing’, or ‘pixel resolution’). For clarity, it may be prudent to avoid using the term ‘resolution’ to describe either the number of samples in an image or the spacing between samples.\nRelated terms: bit-depth, resampling"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Janelia Data Standards",
    "section": "",
    "text": "The Janelia Data Standards group was formed by bioimaging developers who have encountered specific, practical bioimaging data dilemmas for which there is little or no guidance from international community standards. Janelia is excited about international standardization efforts, particularly OME-NGFF. Janelia is contributing to OME-NGFF and is rooting for its success. However, such efforts are not enough, since research experiments may often outpace or even diverge from contemporary community standards. The essays in this collection are meant to fill that gap.\nThis website is Janelia’s bioimaging developers’ manifesto. It is a collection of essays written by developers, for developers, on the advanced technical challenges they’ve encountered. It records the choices Janelia’s developers have made when encountering exotic data, so that those encountering similar situations can make consistent choices."
  },
  {
    "objectID": "about.html#purpose",
    "href": "about.html#purpose",
    "title": "About Janelia Data Standards",
    "section": "",
    "text": "The Janelia Data Standards group was formed by bioimaging developers who have encountered specific, practical bioimaging data dilemmas for which there is little or no guidance from international community standards. Janelia is excited about international standardization efforts, particularly OME-NGFF. Janelia is contributing to OME-NGFF and is rooting for its success. However, such efforts are not enough, since research experiments may often outpace or even diverge from contemporary community standards. The essays in this collection are meant to fill that gap.\nThis website is Janelia’s bioimaging developers’ manifesto. It is a collection of essays written by developers, for developers, on the advanced technical challenges they’ve encountered. It records the choices Janelia’s developers have made when encountering exotic data, so that those encountering similar situations can make consistent choices."
  },
  {
    "objectID": "about.html#style",
    "href": "about.html#style",
    "title": "About Janelia Data Standards",
    "section": "Style",
    "text": "Style\nThe articles in this collection will be vetted, and their conclusions authoritative, for Janelia’s purposes. Where swift, unambiguous decisions are needed, such decisions will be made. The rationale behind those decisions will be explained, and they will become standard practice at Janelia. Contributors are encouraged to remain pragmatic, to describe their use cases, and to share their example data. That being said, where applicable, developers should speak to the abstract design principles that drove their choices."
  },
  {
    "objectID": "about.html#contributing",
    "href": "about.html#contributing",
    "title": "About Janelia Data Standards",
    "section": "Contributing",
    "text": "Contributing\nThis project aims to develop conventions that Janelians need to do their work, and to disseminate those conventions across Janelia. It is not this group’s goal to create a comprehensive textbook, nor to create an international standard. However, as this project matures, contributions to and from the community may be considered. Individuals outside of Janelia who are interested in writing an article should create a GitHub issue to explore this possibility before investing time in it. It is this group’s hope that the rapidly evolving conventions developed here may ultimately, gradually, be considered for incorporation into the OME-NGFF standard as well."
  },
  {
    "objectID": "about.html#structure",
    "href": "about.html#structure",
    "title": "About Janelia Data Standards",
    "section": "Structure",
    "text": "Structure\nThis effort is in its infancy. Ultimately, the project is expected to consist of four components:\n\nWritten articles.\nAn accessible and easily readable website that hosts the articles.\nA glossary and/or thesaurus.\nA directory of example data that the public can view and browse.\n\nWe appreciate the community’s interest in this social experiment."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Introduction to Microscopy File Formats\n\n\n\n\n\nAn opinionated overview of file formats used in microscopy.\n\n\n\n\n\nJan 29, 2025\n\n\nVirginia Scarlett\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "REVIEW_PROCESS.html",
    "href": "REVIEW_PROCESS.html",
    "title": "Introduction",
    "section": "",
    "text": "Articles posted to the Janelia Data Standards website should be vetted, authoritative, well-considered, and of high stylistic and technical quality. For this reason, each new article will undergo a review, using GitHub’s PR and review tooling. This process is intended to help the reviewer refine their ideas."
  },
  {
    "objectID": "REVIEW_PROCESS.html#the-big-picture",
    "href": "REVIEW_PROCESS.html#the-big-picture",
    "title": "Introduction",
    "section": "1. The Big Picture",
    "text": "1. The Big Picture\nIs this article appropriate for the Janelia Data Standards project? 1. Yes 2. No 3. Comments: …\nIs the general premise of the article sound? 1. Yes 2. No 3. Comments: …\nIs the proposed data standard generalizable beyond that author’s particular use case? 1. Yes 2. No 3. Comments: …"
  },
  {
    "objectID": "REVIEW_PROCESS.html#technical-choices",
    "href": "REVIEW_PROCESS.html#technical-choices",
    "title": "Introduction",
    "section": "2. Technical Choices",
    "text": "2. Technical Choices\nIs the proposed standard elegant, straightforward, and focused? 1. Yes 2. No 3. Comments: …\nDoes the author adequately explain the rationale behind the standard? 1. Yes 2. No 3. Comments: …\nIs the author making any flawed implicit assumptions, either about the problem or about their audience? 1. Yes 2. No 3. Comments: …\nDoes the author provide an implementation and/or example data (preferable but not required)? 1. Yes 2. No 3. N/A 4. Comments: …"
  },
  {
    "objectID": "REVIEW_PROCESS.html#writing-style",
    "href": "REVIEW_PROCESS.html#writing-style",
    "title": "Introduction",
    "section": "3. Writing Style",
    "text": "3. Writing Style\nIs the post readable to bio-imaging developers who may come from a different sub-field, or code in a different language? 1. Yes 2. No 3. Comments: …\nDoes it contain any typos or awkward sentences? 1. Yes 2. No 3. Comments: …\nAre the ideas organized in a logical flow? 1. Yes 2. No 3. Comments: …"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "This is a nascent project to unify bioimaging data conventions at HHMI’s Janelia Research Campus.\n\n\n\nThe Janelia Research Campus, Ashburn VA"
  },
  {
    "objectID": "file_formats.html",
    "href": "file_formats.html",
    "title": "Janelia’s Bioimaging File Formats",
    "section": "",
    "text": "Janelia’s Bioimaging File Formats"
  }
]